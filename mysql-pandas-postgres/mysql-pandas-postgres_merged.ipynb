{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b16821-82d2-4758-b96b-78f9372f2daf",
   "metadata": {},
   "source": [
    "## Разбиение ETL-процесса на отдельные файлы в Python\n",
    "Для лучшей организации кода ETL-процесс (Extract-Transform-Load) можно разбить на отдельные модули. Вот как это можно сделать:\n",
    "\n",
    "Рекомендуемая структура проекта\n",
    "\n",
    "etl_project/  \n",
    "├── __init__.py  \n",
    "├── extract.py  \n",
    "├── transform.py  \n",
    "├── load.py  \n",
    "├── main.py  \n",
    "└── utils.py (опционально)  \n",
    "\n",
    "### 1. extract.py - модуль для извлечения данных\n",
    "```python\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "def extract_from_csv(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Извлечение данных из CSV файла\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def extract_from_api(api_url: str, params: Dict[str, Any] = None) -> Dict:\n",
    "    \"\"\"Извлечение данных из API\"\"\"\n",
    "    import requests\n",
    "    response = requests.get(api_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def extract_from_database(query: str, connection_string: str) -> pd.DataFrame:\n",
    "    \"\"\"Извлечение данных из базы данных\"\"\"\n",
    "    import sqlalchemy\n",
    "    engine = sqlalchemy.create_engine(connection_string)\n",
    "    return pd.read_sql(query, engine)\n",
    "```\n",
    "\n",
    "### 2. transform.py - модуль для трансформации данных\n",
    "```python\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Очистка данных\"\"\"\n",
    "    # Удаление дубликатов\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Заполнение пропущенных значений\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('unknown')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_data(df: pd.DataFrame, rules: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Основная трансформация данных\"\"\"\n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # Применение правил трансформации\n",
    "    if 'rename_columns' in rules:\n",
    "        df = df.rename(columns=rules['rename_columns'])\n",
    "    \n",
    "    if 'filter_conditions' in rules:\n",
    "        df = df.query(rules['filter_conditions'])\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "### 3. load.py - модуль для загрузки данных\n",
    "```python\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def load_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"Загрузка данных в CSV файл\"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def load_to_database(df: pd.DataFrame, table_name: str, connection_string: str) -> None:\n",
    "    \"\"\"Загрузка данных в базу данных\"\"\"\n",
    "    import sqlalchemy\n",
    "    engine = sqlalchemy.create_engine(connection_string)\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "def load_to_api(data: Dict, api_url: str) -> None:\n",
    "    \"\"\"Отправка данных через API\"\"\"\n",
    "    import requests\n",
    "    response = requests.post(api_url, json=data)\n",
    "    response.raise_for_status()\n",
    "```\n",
    "\n",
    "### 4. main.py - основной скрипт для запуска ETL\n",
    "```python\n",
    "from extract import extract_from_csv\n",
    "from transform import transform_data\n",
    "from load import load_to_database\n",
    "\n",
    "def run_etl_pipeline():\n",
    "    # Конфигурационные параметры\n",
    "    config = {\n",
    "        'input_file': 'data/input.csv',\n",
    "        'output_db': 'sqlite:///data/output.db',\n",
    "        'output_table': 'processed_data',\n",
    "        'transform_rules': {\n",
    "            'rename_columns': {'old_name': 'new_name'},\n",
    "            'filter_conditions': 'value > 100'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Extract\n",
    "    print(\"Extracting data...\")\n",
    "    raw_data = extract_from_csv(config['input_file'])\n",
    "    \n",
    "    # Transform\n",
    "    print(\"Transforming data...\")\n",
    "    processed_data = transform_data(raw_data, config['transform_rules'])\n",
    "    \n",
    "    # Load\n",
    "    print(\"Loading data...\")\n",
    "    load_to_database(processed_data, config['output_table'], config['output_db'])\n",
    "    \n",
    "    print(\"ETL process completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl_pipeline()\n",
    "```\n",
    "\n",
    "### Дополнительные рекомендации\n",
    "Конфигурация: Вы можете вынести конфигурационные параметры в отдельный файл (например, config.py или settings.yaml).\n",
    "\n",
    "Логирование: Добавьте логирование в каждый этап для отслеживания процесса.\n",
    "\n",
    "Обработка ошибок: Реализуйте обработку ошибок для каждого этапа.\n",
    "\n",
    "Тестирование: Создайте отдельные тесты для каждого модуля.\n",
    "\n",
    "Документация: Добавьте docstrings и комментарии для каждого модуля и функции.\n",
    "\n",
    "Такое разделение делает код более:\n",
    "- Читаемым\n",
    "- Поддерживаемым\n",
    "- Тестируемым\n",
    "- Переиспользуемым\n",
    "- Масштабируемым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d97404-802c-41e0-80da-07b7ead8b46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3556c76b-fd47-44ed-a5b0-ea4ed7444650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debdab24-1fe7-45fa-92d8-a11fb65a7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8cabed-92e3-475c-b19d-640e3c1bfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import mysql_qm \n",
    "from config import postgresql_home "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524f0c9-7a34-482f-90c6-2153a3057f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98662740-a723-4ac2-ad94-71bf14b4325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Боря\\AppData\\Local\\Temp\\ipykernel_18148\\2013417119.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, connection)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT\n",
    "# Забираем данные из БД (в этом примере -с удаленной MySQL)\n",
    "\n",
    "sql_query = '''\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        sales \n",
    "        INNER JOIN companies USING(Артель)\n",
    "        INNER JOIN chaebols USING(Артель)\n",
    "        INNER JOIN industries USING(Товар) \n",
    "        INNER JOIN regions USING(Град)\n",
    "'''\n",
    "\n",
    "with mysql.connector.connect(\n",
    "            host=mysql_qm['host'],\n",
    "            user=mysql_qm['user'], \n",
    "            password=mysql_qm['password'],\n",
    "            database=mysql_qm['database']\n",
    "            ) as connection:\n",
    "    df = pd.read_sql(sql_query, connection)\n",
    "\n",
    "df = df[['Дата', 'Плата', 'Артель', 'Чеболь', 'Товар', 'Промысел', 'Град', 'Царство', ]]\n",
    "\n",
    "df.Дата = pd.to_datetime(df.Дата)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814dc28-de9e-4563-beba-be7aecf40902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811dbf9c-270d-4cf2-bab7-0bb647450e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM\n",
    "# В этом игрушечном примере создаем \"куб\" для сумм продаж\n",
    "\n",
    "cube = df.groupby(['Чеболь', 'Промысел', 'Царство', ]).Плата.sum().round(2).reset_index()\n",
    "cube = cube.rename(columns={'Плата': 'Сумма_продаж'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07361386-16a4-464a-9d33-6ac63d160e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff5cbea-e8f2-4d0b-96cb-bea68222cd34",
   "metadata": {},
   "source": [
    "запишем полученную таблицу в БД Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b686f5e1-61a1-4238-8056-4efd0b04a192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD\n",
    "# [Пере]запишем полученную таблицу в БД Postgres\n",
    "\n",
    "sql_create_query = '''\n",
    "    CREATE TABLE IF NOT EXISTS cube (\n",
    "        Чеболь       VARCHAR(64), \n",
    "        Промысел     VARCHAR(64), \n",
    "        Царство      VARCHAR(64), \n",
    "        Сумма_продаж DECIMAL(10, 2)\n",
    "    )\n",
    "'''\n",
    "\n",
    "with psycopg2.connect(\n",
    "            host=postgresql_home['host'],\n",
    "            user=postgresql_home['user'], \n",
    "            password=postgresql_home['password'],\n",
    "            database=postgresql_home['database']\n",
    "            ) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(sql_create_query)\n",
    "\n",
    "url_object = URL.create(\n",
    "    \"postgresql+psycopg2\",\n",
    "    username=postgresql_home['user'],\n",
    "    password=postgresql_home['password'], \n",
    "    host=postgresql_home['host'],\n",
    "    port=postgresql_home['port'],\n",
    "    database='competition_analysis',\n",
    ")\n",
    "\n",
    "engine = create_engine(url_object)\n",
    "\n",
    "cube.to_sql(\n",
    "    name='cube', # имя таблицы\n",
    "    con=engine,  # движок\n",
    "    if_exists=\"replace\", # если в таблице данные уже есть, заменяем их\n",
    "    index=False # без индекса датафрейма\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76edaf-4ea6-43fd-aef9-c33d71fd0f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
